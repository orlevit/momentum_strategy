{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e5fc31-93fd-4c41-ac6c-2aa13e371e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "sys.path.append(os.path.join('Momentum_additional_files'))\n",
    "\n",
    "from config import *\n",
    "from helper import *\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# price_data_df = collecting_data(START_DATE, END_DATE, DATA_ADJ_CLOSE_LOC, DATA_DIV_LOC)\n",
    "# relative_df = get_relative(price_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc9c489-d8b5-4f7b-bfa3-d0c349ab616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRK.B: possibly delisted; no timezone found\n",
      "$BF.B: possibly delisted; no price data found  (1d 2004-01-01 -> 2024-10-01)\n",
      "[*********************100%***********************]  501 of 501 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AMTM']: IndexError('index 0 is out of bounds for axis 0 with size 0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns that have nan values: 237, and are been dropped.\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date, file_price_loc, file_div_loc = START_DATE, END_DATE, DATA_OPEN_LOC, DATA_DIV_LOC\n",
    "def fetch_sp500_companies():\n",
    "    # Fetch the list of S&P 500 companies from Wikipedia\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Parse the table containing the S&P 500 companies\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Return the list of company symbols\n",
    "    return df['Symbol'].tolist()\n",
    "\n",
    "def get_sp500_companies_active_in_year(start_date, end_date):\n",
    "    # Get the current S&P 500 companies\n",
    "    sp500_companies = fetch_sp500_companies()\n",
    "    \n",
    "    active_companies = []\n",
    "    for symbol in sp500_companies:\n",
    "        try:\n",
    "            # Get historical data for the company\n",
    "            company = yf.Ticker(symbol)\n",
    "            historical_data = company.history(start=start_date, end=end_date)\n",
    "            \n",
    "            # Check if data exists for that year\n",
    "            if not historical_data.empty:\n",
    "                active_companies.append(symbol)\n",
    "        except Exception as e:\n",
    "            # print(f\"Could not retrieve data for {symbol}: {e}\")\n",
    "            pass\n",
    "\n",
    "    return active_companies\n",
    "\n",
    "\n",
    "# Get the list of S&P 500 companies for the year 2004\n",
    "companies_2004 = get_sp500_companies_active_in_year(start_date, end_date)\n",
    "price_data = yf.download(companies_2004, start=start_date, end=end_date, interval='1mo', actions =True)[['Adj Close','Dividends']]\n",
    "num_columns_with_nan = price_data.isnull().any().sum()\n",
    "print(f'The number of columns that have nan values: {num_columns_with_nan}, and are been dropped.')\n",
    "price_data = price_data.dropna(axis=1)\n",
    "price_data[STOCK_TIME].to_csv(file_price_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89927331-1840-4300-8825-c85f9a38d883",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(price_data) \u001b[38;5;241m-\u001b[39m FORMATION_PERIOD_MONTHS):\n\u001b[0;32m----> 2\u001b[0m     block_12 \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(block_12)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'block' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(price_data) - FORMATION_PERIOD_MONTHS):\n",
    "    block_12 = block[:-1]\n",
    "    print(block_12)\n",
    "    break\n",
    "    date_index = block.index[-1]\n",
    "    diff = (block_12[STOCK_TIME].iloc[-1] + block_12['Dividends'].sum(axis=0) - block_12[STOCK_TIME].iloc[0]) / block_12[STOCK_TIME].iloc[0]\n",
    "    row_df = pd.DataFrame(diff).T\n",
    "    row_df.index = [date_index]\n",
    "    relative_df = pd.concat([relative_df, row_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b7246-a5c2-4bd4-b9e1-799bae3ad437",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df) - FORMATION_PERIOD_MONTHS ):\n",
    "    block = df.iloc[i:i + FORMATION_PERIOD_MONTHS + 1] # Add row to get the date index\n",
    "    block_12 = block[:-1]\n",
    "    date_index = block.index[-1]\n",
    "    diff = (block_12[STOCK_TIME].iloc[-1] + block_12['Dividends'].sum(axis=0) - block_12[STOCK_TIME].iloc[0]) / block_12[STOCK_TIME].iloc[0]\n",
    "    row_df = pd.DataFrame(diff).T\n",
    "    row_df.index = [date_index]\n",
    "    relative_df = pd.concat([relative_df, row_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aac484-135d-49f8-bdc2-80e21f5b304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag close\n",
    "# print lag\n",
    "# add technical indicators lagged\n",
    "# fix size window (days instead months?)\n",
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9767997e-39dc-44b1-a017-473233abd0ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miloc[i: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "df.iloc[i: i + 12 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda072e5-51ae-4f5a-9246-fa3532bda114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative(df):\n",
    "    relative_df = pd.DataFrame(columns=df[STOCK_TIME].columns.values)\n",
    "    \n",
    "    for i in range(len(df) - FORMATION_PERIOD_MONTHS ):\n",
    "        block = df.iloc[i:i + FORMATION_PERIOD_MONTHS + 1] # Add row to get the date index\n",
    "        block_12 = block[:-1]\n",
    "        date_index = block.index[-1]\n",
    "        diff = (block_12[STOCK_TIME].iloc[-1] + block_12['Dividends'].sum(axis=0) - block_12[STOCK_TIME].iloc[0]) / block_12[STOCK_TIME].iloc[0]\n",
    "        row_df = pd.DataFrame(diff).T\n",
    "        row_df.index = [date_index]\n",
    "        relative_df = pd.concat([relative_df, row_df])\n",
    "    return relative_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45111696-6bc3-4ef5-bb4d-3154ea6e9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic stock data\n",
    "def create_dummy_stock_data():\n",
    "    np.random.seed(42)\n",
    "    n_days = 1500  # ~6 years of data\n",
    "    dates = pd.date_range(start=\"2015-01-01\", periods=n_days, freq=\"B\")  # Business days\n",
    "    close_prices = np.cumsum(np.random.randn(n_days) * 2 + 100)  # Random walk\n",
    "    volumes = np.random.randint(100, 1000, size=n_days)  # Random volume data\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Date\": dates,\n",
    "        \"Close\": close_prices,\n",
    "        \"Volume\": volumes\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Save the dummy data to a CSV\n",
    "df_dummy = create_dummy_stock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c61c464-9b0a-4c8e-9259-90132af006c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>100.993428</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>200.716900</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>302.012277</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>405.058336</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>504.590030</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>604.121756</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>707.280181</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>808.815051</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>907.876102</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>1008.961222</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>1108.034387</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>1207.102927</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>1307.586852</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Close  Volume\n",
       "0  2015-01-01   100.993428     258\n",
       "1  2015-01-02   200.716900     287\n",
       "2  2015-01-05   302.012277     159\n",
       "3  2015-01-06   405.058336     916\n",
       "4  2015-01-07   504.590030     418\n",
       "5  2015-01-08   604.121756     977\n",
       "6  2015-01-09   707.280181     310\n",
       "7  2015-01-12   808.815051     505\n",
       "8  2015-01-13   907.876102     763\n",
       "9  2015-01-14  1008.961222     208\n",
       "10 2015-01-15  1108.034387     175\n",
       "11 2015-01-16  1207.102927     641\n",
       "12 2015-01-19  1307.586852     413"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "FORMATION_PERIOD_MONTHS=12\n",
    "\n",
    "[i:i + FORMATION_PERIOD_MONTHS + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60916c92-7fb6-4ae2-8340-858202bec0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, optim\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.trend import SMAIndicator\n",
    "from ta.volume import OnBalanceVolumeIndicator\n",
    "\n",
    "# 1. Compute Technical Indicators\n",
    "def compute_technical_indicators(df):\n",
    "    df['RSI'] = RSIIndicator(close=df['Close'], window=14).rsi()\n",
    "    df['MA'] = SMAIndicator(close=df['Close'], window=20).sma_indicator()\n",
    "    bb = BollingerBands(close=df['Close'], window=20)\n",
    "    df['BB_High'] = bb.bollinger_hband()\n",
    "    df['BB_Low'] = bb.bollinger_lband()\n",
    "    df['OBV'] = OnBalanceVolumeIndicator(close=df['Close'], volume=df['Volume']).on_balance_volume()\n",
    "    df = df.dropna()  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# 2. Generate Labels: Buy (1) or Short (0)\n",
    "def generate_labels(df):\n",
    "    df['Future_Close'] = df['Close'].shift(-90)  # 3 months ahead\n",
    "    df['Signal'] = np.where(df['Future_Close'] > df['Close'], 1, 0)\n",
    "    df = df.dropna()  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# 3. Preprocess Data\n",
    "def preprocess_data(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    features = ['RSI', 'MA', 'BB_High', 'BB_Low', 'OBV', 'Close', 'Volume']\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    return df, scaler\n",
    "\n",
    "# 4. Dataset and DataLoader\n",
    "class StockDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, lookback=252):\n",
    "        self.data = data\n",
    "        self.lookback = lookback\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.lookback\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx:idx + self.lookback, :-1].values\n",
    "        y = self.data.iloc[idx + self.lookback, -1]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 5. Define the Model\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, 64, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # 2 classes: Buy or Short\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])\n",
    "        return out\n",
    "\n",
    "# 6. Training and Evaluation\n",
    "def train_model(model, train_loader, val_loader, epochs=20, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        val_loss = evaluate_model(model, val_loader, criterion)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "# 7. Main Workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    df = pd.read_csv('your_stock_data.csv')  # Replace with your data file\n",
    "    df = compute_technical_indicators(df)\n",
    "    df = generate_labels(df)\n",
    "    df, scaler = preprocess_data(df)\n",
    "    \n",
    "    # Split data\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "    train_dataset = StockDataset(train_data)\n",
    "    test_dataset = StockDataset(test_data)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    input_dim = len(train_data.columns) - 1  # Exclude label column\n",
    "    model = StockPredictor(input_dim)\n",
    "    train_model(model, train_loader, val_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d3ed0-839f-471c-8c09-a7d824a94810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
